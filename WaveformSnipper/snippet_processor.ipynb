{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd054e01427aa8be7bec89e51c9856e65d365354790435ad568830a6719ba3e065c",
   "display_name": "Python 3.9.2 64-bit ('main_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard modules\n",
    "import glob\n",
    "import os\n",
    "from joblib import dump\n",
    "import time\n",
    "\n",
    "# External modules\n",
    "from catch22 import catch22_all\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# Internal modules\n",
    "from main import parse_snippet, get_snippet_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_snippet(time_slice: np.ndarray, signal_slice: np.ndarray, title: str = \"\"):\n",
    "    \"\"\"Plots a snippet.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_slice : np.ndarray\n",
    "        time component of slice.\n",
    "    signal_slice : np.ndarray\n",
    "        amplitude component of slice.\n",
    "    title : str\n",
    "        the title of the plot.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.plot(time_slice, signal_slice)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Normalised amplitude\")\n",
    "    plt.ylim([-1.2, 1.2])\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all snippet data into `snippets` dictionary\n",
    "snippets = {}\n",
    "snippet_folder = \"Snippets\"\n",
    "\n",
    "# Find all snippets\n",
    "for snippet_file in glob.glob(f\"{snippet_folder}/*.npy\"):\n",
    "    # Load data\n",
    "    snippet = np.load(snippet_file)\n",
    "    signal_slice, time_slice = parse_snippet(snippet)\n",
    "    event = get_snippet_event(snippet_file)\n",
    "    # Looking at only left and right events\n",
    "    if event != \"left\" and event != \"right\":\n",
    "        continue\n",
    "    # Add data to dictionary\n",
    "    if event not in snippets:\n",
    "        snippets[event] = [(signal_slice, time_slice, snippet_file)]\n",
    "    else:\n",
    "        snippets[event].append((signal_slice, time_slice, snippet_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute catch22 data\n",
    "data = []\n",
    "# Create list of labels and names associated with catch22 data\n",
    "labels = []\n",
    "snippet_names = []\n",
    "for event in snippets:\n",
    "    for signal_slice, _, snippet_filename in snippets[event]:\n",
    "        data.append(catch22_all(signal_slice)[\"values\"])\n",
    "        labels.append(event)\n",
    "        snippet_names.append(snippet_filename)\n",
    "print(f\"There are {len(data)} samples to train/test on.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialise KNN model\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and testing data\n",
    "training_data, test_data, training_labels, test_labels, training_snippet_names, test_snippet_names = train_test_split(data, labels, snippet_names, test_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the training data to the training labels\n",
    "start_time = time.time()\n",
    "model.fit(training_data, training_labels);\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Fitting took {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for test data\n",
    "start_time = time.time()\n",
    "predictions = model.predict(data)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Predictions took {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy and which snippets failed and succeeded\n",
    "count = 0\n",
    "failed = []\n",
    "for idx, prediction in enumerate(predictions):\n",
    "    _, tail = os.path.split(test_snippet_names[idx])\n",
    "    tail = tail.rstrip(\".npy\")\n",
    "    # Compare prediction to label\n",
    "    print(f\"{tail}\\n Prediction: {prediction}\\n Label:      {test_labels[idx]}\\n\")\n",
    "    # Correct prediction\n",
    "    if prediction == test_labels[idx]:\n",
    "        count += 1\n",
    "    # False prediction\n",
    "    else:\n",
    "        failed.append(test_snippet_names[idx])\n",
    "# Print diagnostics\n",
    "print(f\"\\nAccuracy: {100*count/len(predictions):.2f}%\")\n",
    "print(\"The failed snippets are:\")\n",
    "print(*failed, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the failed snippets\n",
    "for snippet_filename in failed:\n",
    "    snippet = np.load(snippet_filename)\n",
    "    signal_slice, time_slice = parse_snippet(snippet)\n",
    "    plot_snippet(time_slice, signal_slice, title=snippet_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing benchmarks\n",
    "predictions = []\n",
    "start_time = time.time()\n",
    "for event in snippets:\n",
    "    for signal_slice, _, snippet_filename in snippets[event]:\n",
    "        data = catch22_all(signal_slice)[\"values\"]\n",
    "        predictions.append(model.predict([data]))\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Takes {elapsed_time:2f} seconds to 'stream' or {elapsed_time/len(predictions):.5f} per second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data, labels)\n",
    "predictions = model.predict(data)\n",
    "# Evaluate accuracy and which snippets failed and succeeded\n",
    "count = 0\n",
    "failed = []\n",
    "for idx, prediction in enumerate(predictions):\n",
    "    _, tail = os.path.split(snippet_names[idx])\n",
    "    tail = tail.rstrip(\".npy\")\n",
    "    # Compare prediction to label\n",
    "    print(f\"{tail}\\n Prediction: {prediction}\\n Label:      {labels[idx]}\\n\")\n",
    "    # Correct prediction\n",
    "    if prediction == labels[idx]:\n",
    "        count += 1\n",
    "    # False prediction\n",
    "    else:\n",
    "        failed.append(snippet_names[idx])\n",
    "# Print diagnostics\n",
    "print(f\"\\nAccuracy: {100*count/len(predictions):.2f}%\")\n",
    "print(\"The failed snippets are:\")\n",
    "print(*failed, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model, \"RFC.joblib\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}